Metadata-Version: 2.4
Name: livekit-plugins-openai
Version: 1.0.11
Summary: Agent Framework plugin for services from OpenAI
Project-URL: Documentation, https://docs.livekit.io
Project-URL: Website, https://livekit.io/
Project-URL: Source, https://github.com/livekit/agents
Author-email: LiveKit <hello@livekit.io>
License-Expression: Apache-2.0
Keywords: audio,livekit,realtime,video,webrtc
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Topic :: Multimedia :: Sound/Audio
Classifier: Topic :: Multimedia :: Video
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.9.0
Requires-Dist: livekit-agents[codecs,images]>=1.0.11
Requires-Dist: openai[realtime]>=1.68.2
Provides-Extra: vertex
Requires-Dist: google-auth>=2.0.0; extra == 'vertex'
Description-Content-Type: text/markdown

# LiveKit Plugins OpenAI

Agent Framework plugin for services from OpenAI. Currently supports STT, TTS, and Dalle 3.

## Installation

```bash
pip install livekit-plugins-openai
```

## Pre-requisites

You'll need an API key from OpenAI. It can be set as an environment variable: `OPENAI_API_KEY`

## OpenAI Beta Features

### Assistants API

In addition to LLM, STT, and TTS, this package also supports using [OpenAI's Assistants API](https://platform.openai.com/docs/assistants/overview) as a LLM.

The Assistants API is a stateful API that holds the conversation state on the server-side.

The `AssistantLLM` class gives you a LLM-like interface to interact with the Assistant API.

For examples of using Assistants API with VoicePipelineAssistant, see the [openai assistants API example](https://github.com/livekit/agents/blob/main/examples/voice-pipeline-agent/openai_assistant.py)
